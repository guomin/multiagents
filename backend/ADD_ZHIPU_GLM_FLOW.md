# æ·»åŠ æ™ºè°±AIï¼ˆGLMï¼‰æµç¨‹

## ğŸ“‹ æ™ºè°±AI API å…³é”®ä¿¡æ¯

### APIç«¯ç‚¹
```
https://open.bigmodel.cn/api/paas/v4
```

**æ³¨æ„**ï¼š
- é€šç”¨APIç«¯ç‚¹ï¼š`https://open.bigmodel.cn/api/paas/v4`
- Codingä¸“å±ç«¯ç‚¹ï¼š`https://open.bigmodel.cn/api/coding/paas/v4`ï¼ˆä»…é™Codingåœºæ™¯ï¼‰

### è®¤è¯æ–¹å¼
```
Authorization: Bearer YOUR_API_KEY
```

### æ”¯æŒçš„æ¨¡å‹ï¼ˆGLMç³»åˆ—ï¼‰

æ ¹æ®æ™ºè°±AIå®˜æ–¹æ–‡æ¡£ï¼Œä¸»è¦æ¨¡å‹åŒ…æ‹¬ï¼š

| æ¨¡å‹åç§° | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|------|---------|
| `glm-4-plus` | æœ€æ–°æœ€å¼ºæ¨¡å‹ | å¤æ‚ä»»åŠ¡ã€åˆ›æ„ç­–åˆ’ |
| `glm-4-0520` | GLM-4ç¨³å®šç‰ˆ | é€šç”¨åœºæ™¯ |
| `glm-4-air` | è½»é‡çº§ï¼Œå¿«é€Ÿå“åº” | ç®€å•ä»»åŠ¡ã€å®æ—¶äº¤äº’ |
| `glm-4-flash` | è¶…å¿«é€Ÿï¼Œä½æˆæœ¬ | å¤§è§„æ¨¡è°ƒç”¨ |
| `glm-4-long` | é•¿æ–‡æœ¬æ”¯æŒï¼ˆ128Kï¼‰ | é•¿æ–‡æ¡£å¤„ç† |
| `glm-3-turbo` | ä¸Šä¸€ä»£æ¨¡å‹ | æˆæœ¬ä¼˜åŒ– |

### APIå…¼å®¹æ€§

âœ… **å¥½æ¶ˆæ¯**ï¼šæ™ºè°±AI API **å®Œå…¨å…¼å®¹OpenAI APIæ ¼å¼**

è¿™æ„å‘³ç€ï¼š
- å¯ä»¥ç›´æ¥ä½¿ç”¨ LangChain çš„ `ChatOpenAI` ç±»
- åªéœ€è¦ä¿®æ”¹ `baseURL` å’Œ `apiKey`
- ä»£ç æ”¹åŠ¨æœ€å°

---

## ğŸš€ æ·»åŠ æµç¨‹ï¼ˆ7æ­¥ï¼‰

### ç¬¬1æ­¥ï¼šæ‰©å±• ModelProvider ç±»å‹

**æ–‡ä»¶**: `backend/src/config/model.ts:1`

```typescript
// ä¿®æ”¹å‰
export type ModelProvider = "openai" | "deepseek";

// ä¿®æ”¹å
export type ModelProvider = "openai" | "deepseek" | "zhipu";
```

---

### ç¬¬2æ­¥ï¼šåœ¨ ModelConfigFactory æ·»åŠ æ™ºè°±AIé…ç½®é€»è¾‘

**æ–‡ä»¶**: `backend/src/config/model.ts:20-45`

åœ¨ `createModelConfig` æ–¹æ³•çš„ `switch` è¯­å¥ä¸­æ·»åŠ  `zhipu` caseï¼š

```typescript
export class ModelConfigFactory {
  static createModelConfig(
    requestedProvider?: ModelProvider,
    modelName?: string,
    temperature: number = 0.7
  ): ModelConfig {
    const provider = (requestedProvider || process.env.MODEL_PROVIDER?.toLowerCase() as ModelProvider) || "openai";

    switch (provider) {
      // ... å…¶ä»– case ...

      case "zhipu":
        if (!process.env.ZHIPU_API_KEY) {
          throw new Error("ZHIPU_API_KEY is required for ZhipuAI provider");
        }
        return {
          provider: "zhipu",
          modelName: modelName || process.env.DEFAULT_MODEL || "glm-4-flash",
          temperature,
          apiKey: process.env.ZHIPU_API_KEY,
          baseURL: process.env.ZHIPU_BASE_URL || "https://open.bigmodel.cn/api/paas/v4"
        };

      // ... å…¶ä»– case ...
    }
  }
}
```

**å…³é”®é…ç½®è¯´æ˜**ï¼š
- `ZHIPU_API_KEY`: æ™ºè°±AIçš„APIå¯†é’¥
- `ZHIPU_BASE_URL`: é»˜è®¤ `https://open.bigmodel.cn/api/paas/v4`
- é»˜è®¤æ¨¡å‹ï¼š`glm-4-flash`ï¼ˆå¿«é€Ÿä¸”ç»æµï¼‰

---

### ç¬¬3æ­¥ï¼šæ›´æ–°å¯ç”¨æ¨¡å‹åˆ—è¡¨

**æ–‡ä»¶**: `backend/src/config/model.ts:48-58`

åœ¨ `getAvailableModels` æ–¹æ³•ä¸­æ·»åŠ æ™ºè°±AIçš„æ¨¡å‹åˆ—è¡¨ï¼š

```typescript
static getAvailableModels(provider?: ModelProvider): string[] {
  const currentProvider = provider || (process.env.MODEL_PROVIDER?.toLowerCase() as ModelProvider) || "openai";

  switch (currentProvider) {
    // ... å…¶ä»– case ...

    case "zhipu":
      return [
        "glm-4-plus",      // æœ€å¼ºæ¨¡å‹
        "glm-4-0520",      // ç¨³å®šç‰ˆ
        "glm-4-air",       // è½»é‡çº§
        "glm-4-flash",     // è¶…å¿«é€Ÿ
        "glm-4-long",      // é•¿æ–‡æœ¬
        "glm-3-turbo"      // ä¸Šä¸€ä»£
      ];

    // ... å…¶ä»– case ...
  }
}
```

---

### ç¬¬4æ­¥ï¼šæ›´æ–°ç¯å¢ƒå˜é‡é…ç½®

**æ–‡ä»¶**: `backend/.env.example`

æ·»åŠ æ™ºè°±AIçš„é…ç½®é¡¹ï¼š

```bash
# ==================== æ™ºè°±AI (GLM) ====================
# è·å–æ–¹å¼ï¼šè®¿é—® https://bigmodel.cn/usercenter/proj-mgmt/apikeys
ZHIPU_API_KEY=your_zhipu_api_key_here
ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4

# é»˜è®¤æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
# æ¨èé€‰é¡¹ï¼š
#   - glm-4-plus: æœ€å¼ºæ¨¡å‹ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡
#   - glm-4-flash: å¿«é€Ÿç»æµï¼Œé€‚åˆå¤§è§„æ¨¡è°ƒç”¨
#   - glm-4-air: å¹³è¡¡æ€§èƒ½å’Œæˆæœ¬
#   - glm-4-long: é•¿æ–‡æœ¬æ”¯æŒï¼ˆ128Kï¼‰
DEFAULT_MODEL_ZHIPU=glm-4-flash
```

**å®é™…ç¯å¢ƒå˜é‡æ–‡ä»¶** (`backend/.env`)ï¼š

```bash
# æ·»åŠ ä½ çš„å®é™…API Key
ZHIPU_API_KEY=your_actual_zhipu_api_key_here
```

---

### ç¬¬5æ­¥ï¼šåˆ›å»ºæ™ºèƒ½ä½“é…ç½®ï¼ˆå¯é€‰ï¼‰

å¦‚æœä½¿ç”¨æ–¹æ¡ˆä¸€ï¼ˆæ™ºèƒ½ä½“é…ç½®æ–‡ä»¶ï¼‰ï¼Œåˆ›å»º `backend/src/config/agent-models.config.ts`ï¼š

```typescript
import { ModelProvider } from './model';

export const AGENT_MODEL_CONFIG: Record<string, {
  provider?: ModelProvider;
  modelName?: string;
  temperature?: number;
}> = {
  // ä½¿ç”¨æ™ºè°±AIçš„æ™ºèƒ½ä½“é…ç½®ç¤ºä¾‹
  curator: {
    provider: "zhipu",
    modelName: "glm-4-plus",      // ç­–åˆ’éœ€è¦æœ€å¼ºæ¨¡å‹
    temperature: 0.8
  },

  spatial_designer: {
    provider: "zhipu",
    modelName: "glm-4-air",       // ç©ºé—´è®¾è®¡ç”¨å¹³è¡¡æ¨¡å‹
    temperature: 0.7
  },

  visual_designer: {
    provider: "zhipu",
    modelName: "glm-4-flash",     // è§†è§‰è®¾è®¡ç”¨å¿«é€Ÿæ¨¡å‹
    temperature: 0.7
  },

  interactive_tech: {
    provider: "zhipu",
    modelName: "glm-4-0520",      // æŠ€æœ¯æ–¹æ¡ˆç”¨ç¨³å®šç‰ˆ
    temperature: 0.5
  },

  budget_controller: {
    provider: "openai",           // é¢„ç®—æ§åˆ¶ä»ç”¨GPT-4
    modelName: "gpt-4-turbo-preview",
    temperature: 0.3
  },

  supervisor: {
    provider: "zhipu",
    modelName: "glm-4-plus",      // åè°ƒéœ€è¦æœ€å¼ºæ¨¡å‹
    temperature: 0.6
  }
};
```

---

### ç¬¬6æ­¥ï¼šæµ‹è¯•éªŒè¯

åˆ›å»ºæµ‹è¯•è„šæœ¬ `backend/test-zhipu.ts`ï¼š

```typescript
import { ModelConfigFactory } from './src/config/model';
import { ChatOpenAI } from '@langchain/openai';
import { HumanMessage } from '@langchain/core/messages';

async function testZhipuAI() {
  console.log('ğŸ§ª å¼€å§‹æµ‹è¯•æ™ºè°±AIé›†æˆ...\n');

  try {
    // 1. åˆ›å»ºæ¨¡å‹é…ç½®
    console.log('1ï¸âƒ£ åˆ›å»ºæ¨¡å‹é…ç½®');
    const modelConfig = ModelConfigFactory.createModelConfig(
      'zhipu',
      'glm-4-flash',
      0.7
    );

    console.log('âœ… é…ç½®åˆ›å»ºæˆåŠŸ:', {
      provider: modelConfig.provider,
      modelName: modelConfig.modelName,
      baseURL: modelConfig.baseURL
    });

    // 2. åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
    console.log('\n2ï¸âƒ£ åˆå§‹åŒ– LLM å®¢æˆ·ç«¯');
    const llm = new ChatOpenAI({
      modelName: modelConfig.modelName,
      temperature: modelConfig.temperature,
      openAIApiKey: modelConfig.apiKey,
      configuration: {
        baseURL: modelConfig.baseURL
      }
    });

    console.log('âœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ');

    // 3. å‘é€æµ‹è¯•è¯·æ±‚
    console.log('\n3ï¸âƒ£ å‘é€æµ‹è¯•è¯·æ±‚');
    const message = new HumanMessage('ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»æ™ºè°±AIçš„GLMæ¨¡å‹ã€‚');

    const startTime = Date.now();
    const response = await llm.invoke([message]);
    const duration = Date.now() - startTime;

    console.log('âœ… è¯·æ±‚æˆåŠŸ');
    console.log('\nğŸ“¤ å“åº”å†…å®¹:');
    console.log(response.content.toString());
    console.log(`\nâ±ï¸  å“åº”æ—¶é—´: ${duration}ms`);

    // 4. æµ‹è¯•ä¸åŒæ¨¡å‹
    console.log('\n4ï¸âƒ£ æµ‹è¯•ä¸åŒæ¨¡å‹');
    const models = ['glm-4-flash', 'glm-4-air', 'glm-4-plus'];

    for (const model of models) {
      console.log(`\næµ‹è¯•æ¨¡å‹: ${model}`);
      const testConfig = ModelConfigFactory.createModelConfig('zhipu', model, 0.7);
      const testLLM = new ChatOpenAI({
        modelName: testConfig.modelName,
        temperature: testConfig.temperature,
        openAIApiKey: testConfig.apiKey,
        configuration: { baseURL: testConfig.baseURL }
      });

      const testStart = Date.now();
      const testResponse = await testLLM.invoke([new HumanMessage('ç®€å•å›å¤ï¼šæµ‹è¯•æˆåŠŸ')]);
      const testDuration = Date.now() - testStart;

      console.log(`âœ… ${model}: ${testDuration}ms`);
    }

    console.log('\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ™ºè°±AIé›†æˆæˆåŠŸï¼');

  } catch (error) {
    console.error('\nâŒ æµ‹è¯•å¤±è´¥:', error);
    process.exit(1);
  }
}

testZhipuAI();
```

**è¿è¡Œæµ‹è¯•**ï¼š
```bash
cd backend
npx ts-node test-zhipu.ts
```

---

### ç¬¬7æ­¥ï¼šåœ¨å®é™…æ™ºèƒ½ä½“ä¸­ä½¿ç”¨

æœ‰ä¸¤ç§ä½¿ç”¨æ–¹å¼ï¼š

#### æ–¹å¼Aï¼šå…¨å±€ä½¿ç”¨æ™ºè°±AI

**æ–‡ä»¶**: `backend/.env`

```bash
# è®¾ç½®é»˜è®¤providerä¸ºæ™ºè°±AI
MODEL_PROVIDER=zhipu
DEFAULT_MODEL=glm-4-flash
```

è¿™æ ·æ‰€æœ‰æ™ºèƒ½ä½“éƒ½ä¼šä½¿ç”¨æ™ºè°±AIï¼ˆé™¤éåœ¨ä»£ç ä¸­ç‰¹åˆ«æŒ‡å®šï¼‰ã€‚

#### æ–¹å¼Bï¼šç‰¹å®šæ™ºèƒ½ä½“ä½¿ç”¨æ™ºè°±AI

**ç¤ºä¾‹ï¼šè®©ç­–åˆ’æ™ºèƒ½ä½“ä½¿ç”¨æ™ºè°±AI**

```typescript
// backend/src/agents/curator.ts

constructor(overrides?: {
  provider?: ModelProvider;
  modelName?: string;
  temperature?: number;
}) {
  // å¦‚æœæ²¡æœ‰æä¾›overrideï¼Œä½¿ç”¨æ™ºè°±AI
  const defaultConfig = {
    provider: 'zhipu' as ModelProvider,
    modelName: 'glm-4-plus',
    temperature: 0.8
  };

  const finalConfig = { ...defaultConfig, ...overrides };

  this.modelConfig = ModelConfigFactory.createModelConfig(
    finalConfig.provider,
    finalConfig.modelName,
    finalConfig.temperature
  );

  // ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
}
```

---

## ğŸ“Š æ™ºè°±AIæ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | èƒ½åŠ› | é€Ÿåº¦ | æˆæœ¬ | é€‚ç”¨æ™ºèƒ½ä½“ |
|------|------|------|------|-----------|
| **glm-4-plus** | â­â­â­â­â­ | â­â­â­ | $$$$ | Curator, Supervisor |
| **glm-4-0520** | â­â­â­â­ | â­â­â­â­ | $$$ | æ‰€æœ‰æ™ºèƒ½ä½“é€šç”¨ |
| **glm-4-air** | â­â­â­â­ | â­â­â­â­ | $$ | Spatial, Interactive |
| **glm-4-flash** | â­â­â­ | â­â­â­â­â­ | $ | Visual, ç®€å•ä»»åŠ¡ |
| **glm-4-long** | â­â­â­â­ | â­â­ | $$$$ | éœ€è¦é•¿æ–‡æœ¬çš„åœºæ™¯ |
| **glm-3-turbo** | â­â­â­ | â­â­â­â­ | $ | æˆæœ¬ä¼˜åŒ– |

---

## ğŸ’° æˆæœ¬å¯¹æ¯”ï¼ˆä¼°ç®—ï¼‰

| Provider | æ¨¡å‹ | è¾“å…¥ï¼ˆå…ƒ/1K tokensï¼‰ | è¾“å‡ºï¼ˆå…ƒ/1K tokensï¼‰ |
|----------|------|---------------------|---------------------|
| æ™ºè°±AI | glm-4-flash | Â¥0.0001 (çº¦$0.000014) | Â¥0.0002 (çº¦$0.000028) |
| æ™ºè°±AI | glm-4-air | Â¥0.0005 | Â¥0.0005 |
| æ™ºè°±AI | glm-4-plus | Â¥0.01 | Â¥0.01 |
| OpenAI | GPT-3.5 Turbo | $0.0005 | $0.0015 |
| OpenAI | GPT-4 Turbo | $0.01 | $0.03 |

**ç»“è®º**ï¼šæ™ºè°±AIçš„ `glm-4-flash` æˆæœ¬æä½ï¼Œéå¸¸é€‚åˆå¤§è§„æ¨¡è°ƒç”¨ã€‚

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. API Key å®‰å…¨

âœ… **æ­£ç¡®åšæ³•**ï¼š
```bash
# åœ¨ .env æ–‡ä»¶ä¸­é…ç½®
ZHIPU_API_KEY=your_api_key_here
```

âŒ **é”™è¯¯åšæ³•**ï¼š
```typescript
// ä¸è¦ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
const apiKey = "your_api_key_here";  // âŒ å±é™©
```

### 2. é”™è¯¯å¤„ç†

æ™ºè°±AIå¯èƒ½ä¼šè¿”å›ç‰¹æ®Šé”™è¯¯ç ï¼Œéœ€è¦å¤„ç†ï¼š

```typescript
try {
  const response = await llm.invoke(messages);
} catch (error: any) {
  if (error.message?.includes('invalid_api_key')) {
    console.error('âŒ API Keyæ— æ•ˆï¼Œè¯·æ£€æŸ¥ ZHIPU_API_KEY');
  } else if (error.message?.includes('rate_limit')) {
    console.error('âŒ è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•');
  } else {
    console.error('âŒ è¯·æ±‚å¤±è´¥:', error.message);
  }
}
```

### 3. æ¨¡å‹é€‰æ‹©å»ºè®®

**æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©**ï¼š

```typescript
const modelMapping = {
  // åˆ›æ„ä»»åŠ¡ - ç”¨æœ€å¼ºæ¨¡å‹
  creative: 'glm-4-plus',

  // æŠ€æœ¯ä»»åŠ¡ - ç”¨ç¨³å®šç‰ˆ
  technical: 'glm-4-0520',

  // ç®€å•ä»»åŠ¡ - ç”¨å¿«é€Ÿç‰ˆ
  simple: 'glm-4-flash',

  // é•¿æ–‡æœ¬ - ç”¨é•¿æ–‡æœ¬æ¨¡å‹
  longContext: 'glm-4-long'
};
```

### 4. å…¼å®¹æ€§æµ‹è¯•

è™½ç„¶æ™ºè°±AIå…¼å®¹OpenAI APIæ ¼å¼ï¼Œä½†ä»éœ€æµ‹è¯•ï¼š

- âœ… åŸºç¡€å¯¹è¯åŠŸèƒ½
- âœ… System prompt æ”¯æŒ
- âœ… Temperature å‚æ•°ç”Ÿæ•ˆ
- âœ… å¤šè½®å¯¹è¯
- âœ… é”™è¯¯å¤„ç†

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹æ¸…å•

- [ ] 1. æ³¨å†Œæ™ºè°±AIè´¦å·ï¼šhttps://bigmodel.cn/
- [ ] 2. è·å–API Keyï¼šhttps://bigmodel.cn/usercenter/proj-mgmt/apikeys
- [ ] 3. æ›´æ–° `.env` æ–‡ä»¶ï¼Œæ·»åŠ  `ZHIPU_API_KEY`
- [ ] 4. ä¿®æ”¹ `model.ts`ï¼Œæ·»åŠ  `zhipu` provider
- [ ] 5. è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯é›†æˆ
- [ ] 6. é…ç½®æ™ºèƒ½ä½“ä½¿ç”¨æ™ºè°±AI
- [ ] 7. æµ‹è¯•å®Œæ•´å·¥ä½œæµ

---

## ğŸš€ ä¸‹ä¸€æ­¥

**é€‰æ‹©ä½ çš„å®æ–½è·¯å¾„**ï¼š

### é€‰é¡¹Aï¼šæœ€å°åŒ–æµ‹è¯•ï¼ˆæ¨èå¼€å§‹ï¼‰
1. åªæ·»åŠ  `zhipu` provider æ”¯æŒ
2. åˆ›å»ºæµ‹è¯•è„šæœ¬
3. éªŒè¯å•ä¸ªæ™ºèƒ½ä½“ï¼ˆå¦‚ Curatorï¼‰
4. æˆåŠŸåæ¨å¹¿åˆ°æ‰€æœ‰æ™ºèƒ½ä½“

**é¢„è®¡æ—¶é—´**ï¼š30åˆ†é’Ÿ

### é€‰é¡¹Bï¼šå®Œæ•´é›†æˆ
1. æ·»åŠ  `zhipu` provider æ”¯æŒ
2. åˆ›å»ºæ™ºèƒ½ä½“é…ç½®æ–‡ä»¶
3. ä¸ºæ¯ä¸ªæ™ºèƒ½ä½“é…ç½®åˆé€‚çš„GLMæ¨¡å‹
4. å…¨é¢æµ‹è¯•

**é¢„è®¡æ—¶é—´**ï¼š1-2å°æ—¶

### é€‰é¡¹Cï¼šæ··åˆé…ç½®ï¼ˆæˆæœ¬ä¼˜åŒ–ï¼‰
1. éƒ¨åˆ†æ™ºèƒ½ä½“ç”¨GLMï¼ˆä¾¿å®œï¼‰
2. æ ¸å¿ƒæ™ºèƒ½ä½“ç”¨GPT-4ï¼ˆè´¨é‡ï¼‰
3. æ ¹æ®æ•ˆæœè°ƒæ•´

**é¢„è®¡æ—¶é—´**ï¼š1å°æ—¶

---

**ä½ æƒ³é€‰æ‹©å“ªä¸ªé€‰é¡¹ï¼Ÿæˆ–è€…æˆ‘ç›´æ¥å¼€å§‹å®æ–½é€‰é¡¹Aï¼ˆæœ€å°åŒ–æµ‹è¯•ï¼‰ï¼Ÿ**
